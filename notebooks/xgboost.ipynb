{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg\n",
    "# import dask.dataframe as dd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pl.read_csv('../data/preprocessed/engineered_training_set.csv')\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort(['srch_id', 'booking_bool', 'click_bool'], descending=[False, True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert polars DataFrames to pandas DataFrames\n",
    "data_pd = data.to_pandas()\n",
    "# replace all NULL values with np.nan\n",
    "data_pd = data_pd.replace('NULL', np.nan)\n",
    "ranking_pd = data_pd[['srch_id', 'prop_id']]\n",
    "\n",
    "# Convert object columns to appropriate data types\n",
    "object_columns = data_pd.select_dtypes(include=['object']).columns\n",
    "data_pd[object_columns] = data_pd[object_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = data_pd.drop(['srch_id'], axis=1)\n",
    "y = ranking_pd['prop_id']\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets based on srch_id\n",
    "srch_ids = data_pd['srch_id'].unique()\n",
    "train_srch_ids, test_srch_ids = train_test_split(srch_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create training and testing DataFrames\n",
    "train_data = data_pd[data_pd['srch_id'].isin(train_srch_ids)]\n",
    "test_data = data_pd[data_pd['srch_id'].isin(test_srch_ids)]\n",
    "\n",
    "# Create training and testing ranking DataFrames\n",
    "train_ranking = ranking_pd[ranking_pd['srch_id'].isin(train_srch_ids)]\n",
    "test_ranking = ranking_pd[ranking_pd['srch_id'].isin(test_srch_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create XGBoost DMatrix objects for training and testing\n",
    "train_dmatrix = xg.DMatrix(\n",
    "    train_data.drop(['srch_id', 'booking_bool', 'gross_bookings_usd', 'position', 'click_bool'], axis=1),\n",
    "    label=train_data['prop_id'],\n",
    "    group=train_data['srch_id'].value_counts().sort_index().values\n",
    ")\n",
    "test_dmatrix = xg.DMatrix(\n",
    "    test_data.drop(['srch_id', 'booking_bool', 'gross_bookings_usd', 'position', 'click_bool'], axis=1),\n",
    "    label=test_data['prop_id'],\n",
    "    group=test_data['srch_id'].value_counts().sort_index().values\n",
    ")\n",
    "\n",
    "# MAKE SURE TO USE FULL DATA SET IN THE END\n",
    "full_dmatrix = xg.DMatrix(\n",
    "    X.drop(['booking_bool', 'gross_bookings_usd', 'position', 'click_bool'], axis=1),\n",
    "    label=y,\n",
    "    group=data_pd['srch_id'].value_counts().sort_index().values\n",
    ")\n",
    "\n",
    "# Set XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'rank:pairwise', # the objective, can also be rank:ndcg, but that is buggy\n",
    "    'lambdarank_pair_method': 'topk', # instead of looking at the mean, we look at the highest k\n",
    "    'lambdarank_num_pair_per_sample': 6, # set slightly higher than intended k\n",
    "    'eval_metric': 'ndcg',\n",
    "    'learning_rate': 0.1,\n",
    "    'max_depth': 10,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Train the XGBoost ranking model\n",
    "model = xg.train(params, train_dmatrix, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg.plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "# evalation\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_pred = model.predict(test_dmatrix)\n",
    "test_data['pred'] = test_pred\n",
    "true_order = test_data[['srch_id', 'prop_id']]\n",
    "\n",
    "# we can order the prop_ids based on the predictions\n",
    "results = test_data.sort_values(['srch_id', 'pred'], ascending=[True, False])[['srch_id', 'prop_id']]\n",
    "\n",
    "grouped = results.groupby('srch_id')['prop_id'].apply(list)\n",
    "grouped = grouped.reset_index()\n",
    "\n",
    "\n",
    "#lambda magic and ugly code\n",
    "grouped['true'] = true_order.groupby('srch_id')['prop_id'].apply(list).reset_index()['prop_id']\n",
    "grouped['ndcg'] = grouped.apply(lambda x: ndcg_score([x['true']], [x['prop_id']], k=5) if len(x['true']) > 1 else None, axis=1)\n",
    "print(f'mean_ndcg: {grouped[\"ndcg\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Full training\n",
    "model = xg.train(params, full_dmatrix, num_boost_round=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "model.save_model('models/model.json')\n",
    "# load the model\n",
    "model = xg.Booster()\n",
    "model.load_model('models/model.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pl.read_csv('../data/preprocessed/engineered_test_set.csv')\n",
    "test_set = test_set.to_pandas()\n",
    "test_set = test_set.replace('NULL', np.nan)\n",
    "\n",
    "object_columns = test_set.select_dtypes(include=['object']).columns\n",
    "test_set[object_columns] = test_set[object_columns].apply(pd.to_numeric, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_dmatrix = xg.DMatrix(test_set.drop(['srch_id'], axis=1), group=test_set['srch_id'].value_counts().sort_index().values)\n",
    "test_set['pred'] = model.predict(test_set_dmatrix)\n",
    "\n",
    "# same as earlier, without need for calculating the ndcg, so less steps\n",
    "submission = test_set.sort_values(['srch_id', 'pred'], ascending=[True, False])[['srch_id', 'prop_id']]\n",
    "submission.to_csv('submit/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# srch_ids = test_set['srch_id'].unique()\n",
    "\n",
    "# # Create an empty DataFrame to store the predictions\n",
    "# submission_df = pd.DataFrame(columns=['srch_id', 'prop_id'])\n",
    "\n",
    "# #  Unique srch_ids in the test set\n",
    "# srch_ids = test_set['srch_id'].unique()\n",
    "\n",
    "# # Pre-allocate a list to collect results\n",
    "# results = []\n",
    "\n",
    "# # Iterate over each srch_id and make predictions\n",
    "# for srch_id in tqdm(srch_ids):\n",
    "#     # Get the data for the current srch_id\n",
    "#     srch_data = test_set[test_set['srch_id'] == srch_id]\n",
    "\n",
    "#     # Create DMatrix for the current srch_id\n",
    "#     srch_dmatrix = xg.DMatrix(srch_data.drop(['srch_id'], axis=1))\n",
    "\n",
    "#     # Make predictions for the current srch_id\n",
    "#     srch_pred = model.predict(srch_dmatrix)\n",
    "\n",
    "#     # Get the corresponding prop_ids for the current srch_id\n",
    "#     srch_prop_ids = srch_data['prop_id'].values\n",
    "\n",
    "#     # Sort the prop_ids based on the predicted scores\n",
    "#     sorted_indices = np.argsort(srch_pred)[::-1]\n",
    "#     sorted_prop_ids = srch_prop_ids[sorted_indices]\n",
    "\n",
    "#     # Collect the results for the current srch_id\n",
    "#     results.append(pd.DataFrame({'srch_id': srch_id, 'prop_id': sorted_prop_ids}))\n",
    "\n",
    "# # Concatenate all results into a single DataFrame\n",
    "# submission_df = pd.concat(results, ignore_index=True)\n",
    "\n",
    "\n",
    "# # Check final submission DataFrame size\n",
    "# print(f\"Expected number of entries: {len(test_set)}\")\n",
    "# print(f\"Actual number of entries: {len(submission_df)}\")\n",
    "\n",
    "# # Save the submission DataFrame to a CSV file\n",
    "# submission_df.to_csv('submit/submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ComputationalEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
